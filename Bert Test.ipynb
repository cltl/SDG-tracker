{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0218 13:40:56.581317  1140 file_utils.py:35] PyTorch version 1.4.0 available.\n",
      "I0218 13:41:13.361604  1140 SentenceTransformer.py:29] Load pretrained SentenceTransformer: bert-base-nli-mean-tokens\n",
      "I0218 13:41:13.361604  1140 SentenceTransformer.py:32] Did not find a / or \\ in the name. Assume to download model from server\n",
      "I0218 13:41:13.377212  1140 SentenceTransformer.py:68] Load SentenceTransformer from folder: C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\n",
      "I0218 13:41:13.446007  1140 configuration_utils.py:182] loading configuration file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\config.json\n",
      "I0218 13:41:13.461637  1140 configuration_utils.py:199] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0218 13:41:13.461637  1140 modeling_utils.py:403] loading weights file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\pytorch_model.bin\n",
      "I0218 13:41:18.980147  1140 tokenization_utils.py:327] Model name 'C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming 'C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT' is a path or url to a directory containing tokenizer files.\n",
      "I0218 13:41:18.990654  1140 tokenization_utils.py:359] Didn't find file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\tokenizer_config.json. We won't load it.\n",
      "I0218 13:41:18.997159  1140 tokenization_utils.py:395] loading file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\vocab.txt\n",
      "I0218 13:41:19.007166  1140 tokenization_utils.py:395] loading file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\added_tokens.json\n",
      "I0218 13:41:19.011669  1140 tokenization_utils.py:395] loading file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\special_tokens_map.json\n",
      "I0218 13:41:19.163777  1140 tokenization_utils.py:395] loading file None\n",
      "I0218 13:41:19.594443  1140 SentenceTransformer.py:89] Use pytorch device: cpu\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  2.74it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = ['I am a dog.']\n",
    "sentence_embeddings = model.encode(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "Sentence: I am a dog.\n",
      "Embedding: [ 3.91739845e-01  7.04850614e-01  1.20507681e+00 -4.01438147e-01\n",
      "  1.14844099e-01  8.50133240e-01  7.65740037e-01 -9.74929512e-01\n",
      " -2.20095605e-01 -4.03584629e-01 -1.01304507e+00  5.06959498e-01\n",
      "  1.96294278e-01  3.47946584e-01  4.74058598e-01  3.83293092e-01\n",
      " -4.08543885e-01 -2.98515975e-01  5.90913355e-01 -4.77737516e-01\n",
      " -8.16412270e-01 -1.31126419e-01 -9.83216226e-01 -7.03829587e-01\n",
      "  2.79261582e-02  8.43549371e-01  6.58015370e-01  6.35251880e-01\n",
      " -1.39742088e+00  2.29173616e-01  6.27867818e-01 -1.18884158e+00\n",
      "  5.63775182e-01  4.25893396e-01  1.35116503e-01  6.17332086e-02\n",
      " -2.05235079e-01 -1.01548776e-01  1.14549078e-01 -6.09708786e-01\n",
      "  6.02659702e-01  8.98217142e-01  1.99049070e-01  7.90203214e-01\n",
      " -6.51363671e-01  2.35329699e-02 -8.95616472e-01  6.74230933e-01\n",
      "  6.55712485e-01 -1.14780104e+00 -2.12683901e-01 -5.17640710e-01\n",
      " -1.69861186e+00  3.32220614e-01 -9.08482671e-01  1.54743835e-01\n",
      "  4.90299016e-01 -1.22362840e+00 -8.87100816e-01  4.71355394e-02\n",
      "  3.49942952e-01  8.16011503e-02  1.15248036e+00  5.01600444e-01\n",
      " -3.42296898e-01  8.88657928e-01 -4.46687967e-01 -3.12139064e-01\n",
      " -2.67653257e-01  1.26868093e+00  1.12919426e+00 -5.56126177e-01\n",
      " -5.77448070e-01  4.20141071e-01 -9.82515931e-01 -1.28070295e+00\n",
      "  8.03752601e-01  4.71158952e-01  1.07849562e+00  1.15202999e+00\n",
      "  1.14330041e+00  6.10356152e-01  6.51938140e-01  3.14685069e-02\n",
      " -3.51980403e-02  2.61366457e-01  1.26398578e-02 -7.79984146e-02\n",
      " -1.48612702e+00  6.60461187e-02  4.49740961e-02  5.67891262e-02\n",
      "  5.12162745e-01  5.49336255e-01  5.60510218e-01 -1.80740923e-01\n",
      " -2.95773923e-01  2.61377037e-01  2.99599230e-01 -6.84661329e-01\n",
      " -4.87896055e-01 -1.72060207e-01 -9.69438136e-01 -3.45406055e-01\n",
      " -1.16116539e-01  1.25569910e-01 -3.52445036e-01 -6.61632001e-01\n",
      " -6.02918267e-01  3.05964381e-01  6.14548735e-02 -4.39171374e-01\n",
      " -3.86740528e-02  3.80643338e-01  6.11527078e-02  5.40128648e-01\n",
      " -7.77232468e-01  6.00236297e-01  1.70964584e-01  4.81616974e-01\n",
      " -5.30580401e-01  4.03393060e-01 -1.17356265e+00 -4.49621707e-01\n",
      " -1.82436705e-02 -6.23668015e-01 -5.05817354e-01  1.04578719e-01\n",
      " -1.38022327e+00 -3.00844163e-01 -2.12729096e-01  9.18326199e-01\n",
      "  7.90266931e-01  7.58018866e-02 -2.60479361e-01  3.80182743e-01\n",
      "  5.15496433e-01 -6.59282684e-01 -1.19237483e+00 -4.57193077e-01\n",
      " -9.22805667e-01  3.10720295e-01 -3.54525775e-01  2.82374680e-01\n",
      " -4.22978669e-01 -2.71882415e-01  6.35165215e-01  3.96340162e-01\n",
      " -3.36747408e-01  1.64516419e-01 -2.13975832e-01  1.02656722e+00\n",
      " -4.69899148e-01 -6.15424693e-01 -7.13519752e-01 -4.14322853e-01\n",
      " -1.05741465e+00  4.47221756e-01  1.10127330e-02 -2.58514553e-01\n",
      "  5.30815482e-01 -5.25231302e-01 -4.50738370e-01  2.48792857e-01\n",
      "  1.09136164e+00 -5.43154716e-01 -2.12570116e-01 -4.64915365e-01\n",
      " -5.33278465e-01 -4.73308027e-01  6.75576687e-01 -1.23357987e+00\n",
      " -4.08307552e-01  9.24318194e-01  4.09538060e-01 -1.86012357e-01\n",
      "  5.10079086e-01  5.88065505e-01  2.61618346e-01 -8.63191605e-01\n",
      " -4.34572399e-01 -1.72107667e-01  8.66519094e-01 -3.73881131e-01\n",
      "  4.06181902e-01 -5.30627549e-01 -3.93643290e-01 -4.46944028e-01\n",
      " -8.19517225e-02  1.59277111e-01 -1.14173913e+00 -1.51586068e+00\n",
      "  1.20671654e+00 -6.75389111e-01  4.88669097e-01 -9.97827232e-01\n",
      " -3.05512488e-01 -1.26830295e-01  5.48374727e-02  1.86361089e-01\n",
      " -4.25165504e-01 -9.89343584e-01  1.03684294e+00 -3.99968833e-01\n",
      "  8.33105743e-01  1.41162658e+00  1.40153855e-01  6.89409137e-01\n",
      " -1.16120167e-01 -1.60278440e-01  5.09470522e-01  3.98135513e-01\n",
      " -9.49779227e-02  1.73333645e-01 -9.80912820e-02 -6.57956421e-01\n",
      "  5.90177596e-01 -5.60887039e-01 -9.85108167e-02  2.85832793e-01\n",
      "  2.04820171e-01  7.58063868e-02 -5.28053582e-01  2.14940429e-01\n",
      " -3.30183178e-01 -1.91322178e-01  5.29784739e-01 -4.76252109e-01\n",
      "  2.36918926e-01 -2.84232020e-01  4.16517884e-01  6.02258630e-02\n",
      " -6.18592620e-01  5.34489691e-01  2.35206947e-01  1.26318291e-01\n",
      "  8.91096175e-01  5.68306260e-02  4.11559165e-01 -4.58269706e-03\n",
      "  1.31547070e+00  1.13748085e+00 -1.07099056e-01 -2.68549938e-02\n",
      " -1.34370303e+00 -7.09942639e-01  1.41350961e+00  1.18388367e+00\n",
      " -9.63674366e-01 -2.85375625e-01  1.56890869e-01 -1.30243564e+00\n",
      "  6.87971652e-01 -1.00512505e+00 -9.39517990e-02 -2.84263402e-01\n",
      " -9.24052417e-01  8.11543223e-03 -1.89164653e-01 -1.25723553e+00\n",
      " -2.22507748e-03 -7.31033742e-01 -1.20239544e+00 -1.04749990e+00\n",
      "  6.42706780e-03  2.83107281e-01 -7.97650218e-01  2.41781965e-01\n",
      "  4.89791125e-01  6.93592131e-01 -7.49939829e-02  7.67951310e-01\n",
      " -4.72172737e-01 -3.76814097e-01  5.56645453e-01  4.77719843e-01\n",
      "  1.27548850e+00 -1.24393292e-01 -3.66625696e-01  2.77413189e-01\n",
      " -5.30261517e-01 -2.01588258e-01 -1.05939102e+00 -2.39534944e-01\n",
      "  2.70246834e-01 -7.97366679e-01  4.01168793e-01 -1.49648392e+00\n",
      " -1.04173863e+00  2.88992912e-01  1.00605763e-01  5.96604466e-01\n",
      " -5.46617471e-02 -7.55616248e-01  4.52196777e-01  1.81873471e-01\n",
      "  6.99349105e-01 -1.00505579e+00 -5.92433572e-01  3.37213457e-01\n",
      " -3.33958060e-01 -5.47864735e-01  1.10331647e-01  1.87286243e-01\n",
      "  7.57114708e-01 -2.25639969e-01  2.64975041e-01  1.05884385e+00\n",
      " -1.55243623e+00 -2.62298822e-01 -8.94789875e-01 -4.15505379e-01\n",
      "  1.24780215e-01  7.60294273e-02  7.26952329e-02  3.74251366e-01\n",
      " -2.34129027e-01  1.15156007e+00 -2.64712334e-01 -7.10146308e-01\n",
      "  1.35448050e+00 -5.50058484e-01  2.91799068e-01 -3.44215333e-01\n",
      "  1.29569665e-01 -8.75337198e-02 -1.05097663e+00  1.35427821e+00\n",
      "  2.92461365e-01 -1.38762563e-01  3.78303558e-01 -1.72897860e-01\n",
      " -1.95915371e-01  2.59184986e-01 -9.98999178e-01  1.34105372e+00\n",
      "  3.84693481e-02 -1.53836355e-01  9.43484485e-01  4.46743071e-01\n",
      " -2.54307777e-01 -7.81469405e-01  4.72075641e-01 -1.79181412e-01\n",
      "  1.79751468e+00 -7.41979200e-03 -7.97404826e-01 -7.13939846e-01\n",
      "  6.48794591e-01 -1.07529902e+00 -9.85406991e-03 -8.06212544e-01\n",
      " -5.00939012e-01 -4.59267557e-01 -7.34795511e-01 -4.92378384e-01\n",
      "  4.75491703e-01 -1.24484137e-01  2.06417054e-01  5.62272489e-01\n",
      "  2.04778939e-01  1.32493496e+00  6.25743449e-01 -4.42202568e-01\n",
      "  1.71203166e-01 -6.77248418e-01  4.73489761e-01  6.31001115e-01\n",
      "  4.37475950e-01 -7.79667079e-01  1.41915530e-01 -7.78501689e-01\n",
      "  4.88299519e-01  1.85056373e-01  7.70363286e-02 -7.77514160e-01\n",
      " -1.54607260e+00 -4.21128005e-01 -6.35726079e-02  3.87030602e-01\n",
      "  2.45053455e-01 -1.06315780e+00  4.78352219e-01 -3.60213965e-01\n",
      " -1.81037374e-02  4.65242654e-01  1.01430630e-02 -1.14180875e+00\n",
      "  2.39719242e-01 -1.72944479e-02 -3.29479396e-01  1.47780523e-01\n",
      "  2.09723487e-01 -1.11114927e-01  3.38646173e-01 -1.02639461e+00\n",
      "  7.62913764e-01  6.27165735e-01  7.66922355e-01  3.52857597e-02\n",
      " -6.02591157e-01  7.12655634e-02  1.28736436e+00 -1.06082046e+00\n",
      "  2.54866749e-01 -7.79618680e-01  1.07307948e-01  3.66365939e-01\n",
      " -4.13303763e-01 -1.62356451e-01 -7.45117292e-02  7.71231875e-02\n",
      "  4.46703672e-01 -4.70101446e-01 -5.26459157e-01  7.77448654e-01\n",
      "  1.45328224e+00 -2.48183697e-01  2.65624700e-03  2.52444088e-01\n",
      " -3.17780763e-01 -7.34893680e-01 -2.31984258e-01  6.94212258e-01\n",
      " -3.22438747e-01 -3.75604838e-01 -5.49222305e-02 -3.27660143e-01\n",
      " -7.46417418e-02  6.06441535e-02  5.76183140e-01  5.22479534e-01\n",
      " -1.16951442e+00  3.91072422e-01  5.76143801e-01 -4.54074442e-01\n",
      "  2.72301614e-01  8.78847018e-02  1.46757394e-01  1.03108227e+00\n",
      "  1.09207369e-01  9.69326571e-02 -7.35035360e-01  5.94983876e-01\n",
      "  6.20779037e-01 -7.58377612e-01  8.33595842e-02 -1.16372311e+00\n",
      " -5.48399031e-01  5.70186734e-01  5.90093672e-01  1.49652615e-01\n",
      " -9.41794693e-01  2.25177273e-01  7.59181559e-01 -3.19694370e-01\n",
      "  5.21349430e-01 -5.15648425e-01  3.65999967e-01 -1.01741886e+00\n",
      " -1.76633485e-02  1.15957379e-01 -8.04337412e-02 -5.77618062e-01\n",
      "  5.79798281e-01  6.09873474e-01 -7.61341095e-01  5.56662381e-01\n",
      " -1.29630715e-01  1.58251062e-01  1.84673667e-01 -5.18547833e-01\n",
      "  3.92715126e-01  6.04775622e-02  7.75700152e-01 -1.03650093e-01\n",
      " -7.61577010e-01 -1.19997241e-01 -1.15842514e-01  3.14635560e-02\n",
      "  2.82662660e-02  4.41159010e-01 -4.82560784e-01 -2.73158461e-01\n",
      " -6.20862067e-01  3.31073582e-01  2.17119128e-01 -3.36322859e-02\n",
      "  8.72449517e-01  2.39046603e-01  9.44716632e-01 -5.18323958e-01\n",
      "  2.46911779e-01 -6.65146828e-01  3.67914528e-01 -1.23261167e-02\n",
      " -3.95702153e-01  7.00773120e-01 -1.72424316e-01  3.37064594e-01\n",
      " -1.33421645e-01  7.28636622e-01 -8.92871976e-01 -1.74336895e-01\n",
      "  2.87873656e-01  2.60334849e-01  3.93543780e-01 -3.69792134e-01\n",
      " -5.32666862e-01  6.44695342e-01 -3.39307696e-01  8.70680138e-02\n",
      "  6.11950219e-01 -1.29234031e-01 -7.71792412e-01 -9.60026458e-02\n",
      " -3.55145931e-01 -3.49978834e-01  2.72109117e-02 -4.89010483e-01\n",
      "  1.09773505e+00 -4.81039345e-01 -1.19284141e+00 -5.74612580e-02\n",
      "  3.11820120e-01  1.32858384e+00 -1.31176993e-01 -9.48053598e-02\n",
      "  5.41419089e-01 -5.33891730e-02 -6.00250900e-01 -2.15800837e-01\n",
      " -3.75350028e-01  6.20998740e-01 -6.77049816e-01  9.24995720e-01\n",
      " -6.79225802e-01 -1.17643571e+00 -1.12217121e-01  1.14914276e-01\n",
      "  1.00404179e+00 -6.79878145e-02  2.15945914e-01 -7.36238897e-01\n",
      " -1.04230261e+00  8.98039281e-01  9.06051844e-02 -3.57021004e-01\n",
      "  7.66372323e-01  1.92569606e-02  5.33704102e-01  3.70415479e-01\n",
      "  3.94082010e-01 -3.12530816e-01 -8.94646943e-01  4.10512649e-02\n",
      " -1.91754609e-01  7.58426726e-01 -2.66737998e-01  9.11373556e-01\n",
      " -1.51050642e-01  4.26805496e-01 -6.30967617e-01  4.39343542e-01\n",
      " -8.09961200e-01  3.22052956e-01 -3.74697149e-01  5.09188473e-01\n",
      "  6.82545125e-01  1.46976221e+00 -5.71942329e-01 -3.54567051e-01\n",
      " -6.04240596e-02  9.56322193e-01 -1.03894496e+00 -1.01781571e+00\n",
      "  4.10443574e-01  3.85781944e-01 -7.57041872e-01 -1.41137376e-01\n",
      "  7.26832688e-01  7.47962773e-01 -6.25950545e-02 -1.26605660e-01\n",
      " -9.13116395e-01  6.09640777e-01  4.54482019e-01 -4.87214625e-01\n",
      "  5.36693990e-01  2.08491966e-01  7.64526665e-01 -4.66651469e-01\n",
      "  1.23296633e-01  1.74950480e-01  1.50640810e+00  2.36182317e-01\n",
      " -1.02552438e+00  6.48238480e-01  1.17213905e-01 -5.80456071e-02\n",
      "  8.81553739e-02 -3.69650215e-01 -2.03563467e-01  4.70964223e-01\n",
      " -6.54593587e-01  9.99274999e-02 -3.58426794e-02  8.67130876e-01\n",
      " -5.61203897e-01  7.89734364e-01  3.71331513e-01 -8.25867772e-01\n",
      " -2.59523571e-01 -7.51100123e-01  7.38080800e-01 -1.14586580e+00\n",
      " -1.15436509e-01  7.00382411e-01  5.89009941e-01  1.92375436e-01\n",
      " -2.06002921e-01  2.23930642e-01 -4.05628264e-01 -5.02863884e-01\n",
      " -1.02388717e-01 -9.75009143e-01  4.58536595e-01  1.58778891e-01\n",
      " -4.92341489e-01 -5.61825573e-01  1.48978621e-01  3.84250015e-01\n",
      " -2.62865752e-01 -3.72539699e-01 -1.03371882e+00  1.19120610e+00\n",
      " -3.26166525e-02 -3.54536712e-01  5.94697118e-01 -4.07304972e-01\n",
      "  1.28654018e-01 -9.33616683e-02  2.70662338e-01  2.86535472e-01\n",
      "  5.58934033e-01  5.49302876e-01  2.77525246e-01  1.05894232e+00\n",
      " -3.42647225e-01  1.12797923e-01 -4.83142704e-01  1.27649561e-01\n",
      " -5.82004130e-01  5.97472191e-01 -3.03280979e-01 -1.25908002e-01\n",
      "  4.33952421e-01  9.66403186e-01  4.23820823e-01 -9.53575253e-01\n",
      "  3.31934154e-01 -8.83150846e-02 -9.90562558e-01 -3.46118957e-01\n",
      "  1.49084896e-01 -1.35828108e-01 -9.22881007e-01  2.25478541e-02\n",
      " -2.70359665e-01  3.11146647e-01  6.37583256e-01  8.09521079e-02\n",
      "  3.04451138e-01  3.65180597e-02 -1.95333406e-01 -8.87469411e-01\n",
      "  1.47871709e+00  1.29497445e+00 -4.32602495e-01  7.09463298e-01\n",
      "  2.90719211e-01  5.17240882e-01  3.58077914e-01 -1.98082790e-01\n",
      "  3.27079087e-01 -3.04736853e-01 -8.40428948e-01 -8.20989311e-01\n",
      " -4.82271045e-01  2.72920609e-01  1.14019528e-01 -5.40190220e-01\n",
      " -3.09351861e-01 -9.56183374e-01 -3.25545788e-01  3.27429682e-01\n",
      " -1.84111539e-02 -3.59644890e-01  4.44989115e-01 -8.55586469e-01\n",
      " -2.28357151e-01  1.28678754e-01  2.45465767e-02 -1.39249790e+00\n",
      " -1.19917945e-03 -7.34125555e-01  4.29784447e-01 -3.17699909e-01\n",
      " -2.13514969e-01  6.04173124e-01 -1.28395885e-01  2.54287630e-01\n",
      "  6.31418228e-01  2.22647399e-01  1.08189926e-01  8.33218992e-01\n",
      "  3.88987720e-01 -1.11416988e-01  8.37133110e-01 -6.99545681e-01\n",
      " -2.09785491e-01  1.53613210e-01 -4.02092069e-01  1.06662583e+00\n",
      "  7.01607049e-01 -6.01942897e-01 -4.66395676e-01 -1.60493299e-01\n",
      "  2.98703372e-01 -3.39695513e-01 -1.30900025e-01  3.31245512e-01\n",
      " -1.11169279e+00 -5.62798977e-02  5.46573758e-01 -7.33631670e-01\n",
      " -9.94295955e-01 -3.92875940e-01  1.69029623e-01 -1.61894113e-01\n",
      " -7.49014854e-01 -9.31475759e-01  2.52579987e-01 -4.46674764e-01\n",
      "  3.45476717e-01 -2.68391550e-01  1.74560219e-01  1.30631015e-01\n",
      " -5.59190392e-01  8.93121839e-01  2.73337662e-01  1.18452752e+00\n",
      " -4.42510039e-01 -3.67991142e-02  1.18308254e-01  4.90195185e-01\n",
      " -7.45643973e-01 -3.60041291e-01  3.88268441e-01  5.82628310e-01\n",
      "  2.69931287e-01 -1.46457568e-01 -1.67690516e-01 -3.84638131e-01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.38154107e-02 -3.81042957e-01  7.32615367e-02  5.15558839e-01]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sentence, embedding in zip(sentences, sentence_embeddings):\n",
    "    print(len(embedding))\n",
    "    print(\"Sentence:\", sentence)\n",
    "    print(\"Embedding:\", embedding)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0218 13:41:20.258465  1140 SentenceTransformer.py:29] Load pretrained SentenceTransformer: bert-base-nli-mean-tokens\n",
      "I0218 13:41:20.258465  1140 SentenceTransformer.py:32] Did not find a / or \\ in the name. Assume to download model from server\n",
      "I0218 13:41:20.274088  1140 SentenceTransformer.py:68] Load SentenceTransformer from folder: C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\n",
      "I0218 13:41:20.285101  1140 configuration_utils.py:182] loading configuration file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\config.json\n",
      "I0218 13:41:20.290605  1140 configuration_utils.py:199] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0218 13:41:20.294108  1140 modeling_utils.py:403] loading weights file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\pytorch_model.bin\n",
      "I0218 13:41:25.998462  1140 tokenization_utils.py:327] Model name 'C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming 'C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT' is a path or url to a directory containing tokenizer files.\n",
      "I0218 13:41:26.003467  1140 tokenization_utils.py:359] Didn't find file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\tokenizer_config.json. We won't load it.\n",
      "I0218 13:41:26.006968  1140 tokenization_utils.py:395] loading file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\vocab.txt\n",
      "I0218 13:41:26.011973  1140 tokenization_utils.py:395] loading file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\added_tokens.json\n",
      "I0218 13:41:26.021480  1140 tokenization_utils.py:395] loading file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\special_tokens_map.json\n",
      "I0218 13:41:26.035489  1140 tokenization_utils.py:395] loading file None\n",
      "I0218 13:41:26.281999  1140 SentenceTransformer.py:89] Use pytorch device: cpu\n",
      "Batches: 100%|███████████████████████████████████| 2/2 [00:00<00:00,  2.11it/s]\n",
      "Batches: 100%|███████████████████████████████████| 1/1 [00:00<00:00,  3.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A man is eating pasta.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A man is eating a piece of bread. (Score: 0.8480)\n",
      "A man is eating food. (Score: 0.7759)\n",
      "Two men pushed carts through the woods. (Score: 0.2095)\n",
      "A monkey is playing drums. (Score: 0.1945)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1586)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: Someone in a gorilla costume is playing a set of drums.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A monkey is playing drums. (Score: 0.7985)\n",
      "A cheetah is running behind its prey. (Score: 0.2860)\n",
      "The girl is carrying a baby. (Score: 0.2351)\n",
      "A man is riding a horse. (Score: 0.2023)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.1963)\n",
      "\n",
      "\n",
      "======================\n",
      "\n",
      "\n",
      "Query: A cheetah chases prey on across a field.\n",
      "\n",
      "Top 5 most similar sentences in corpus:\n",
      "A cheetah is running behind its prey. (Score: 0.9007)\n",
      "Two men pushed carts through the woods. (Score: 0.3662)\n",
      "A monkey is playing drums. (Score: 0.3061)\n",
      "A man is riding a horse. (Score: 0.2930)\n",
      "A man is riding a white horse on an enclosed ground. (Score: 0.2718)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a simple application for sentence embeddings: semantic search\n",
    "We have a corpus with various sentences. Then, for a given query sentence,\n",
    "we want to find the most similar sentence in this corpus.\n",
    "This script outputs for various queries the top 5 most similar sentences in the corpus.\n",
    "\"\"\"\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import scipy.spatial\n",
    "\n",
    "embedder = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'A man is riding a horse.',\n",
    "          'A woman is playing violin.',\n",
    "          'Two men pushed carts through the woods.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'A cheetah is running behind its prey.'\n",
    "          ]\n",
    "corpus_embeddings = embedder.encode(corpus)\n",
    "\n",
    "# Query sentences:\n",
    "queries = ['A man is eating pasta.', 'Someone in a gorilla costume is playing a set of drums.', 'A cheetah chases prey on across a field.']\n",
    "query_embeddings = embedder.encode(queries)\n",
    "\n",
    "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\n",
    "closest_n = 5\n",
    "for query, query_embedding in zip(queries, query_embeddings):\n",
    "    distances = scipy.spatial.distance.cdist([query_embedding], corpus_embeddings, \"cosine\")[0]\n",
    "\n",
    "    results = zip(range(len(distances)), distances)\n",
    "    results = sorted(results, key=lambda x: x[1])\n",
    "\n",
    "    print(\"\\n\\n======================\\n\\n\")\n",
    "    print(\"Query:\", query)\n",
    "    print(\"\\nTop 5 most similar sentences in corpus:\")\n",
    "\n",
    "    for idx, distance in results[0:closest_n]:\n",
    "        print(corpus[idx].strip(), \"(Score: %.4f)\" % (1-distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0218 13:49:50.366529  1140 SentenceTransformer.py:29] Load pretrained SentenceTransformer: bert-base-nli-mean-tokens\n",
      "I0218 13:49:50.382154  1140 SentenceTransformer.py:32] Did not find a / or \\ in the name. Assume to download model from server\n",
      "I0218 13:49:50.397780  1140 SentenceTransformer.py:68] Load SentenceTransformer from folder: C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\n",
      "I0218 13:49:50.429030  1140 configuration_utils.py:182] loading configuration file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\config.json\n",
      "I0218 13:49:50.429030  1140 configuration_utils.py:199] Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"finetuning_task\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"is_decoder\": false,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"num_labels\": 2,\n",
      "  \"output_attentions\": false,\n",
      "  \"output_hidden_states\": false,\n",
      "  \"output_past\": true,\n",
      "  \"pruned_heads\": {},\n",
      "  \"torchscript\": false,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_bfloat16\": false,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "I0218 13:49:50.444655  1140 modeling_utils.py:403] loading weights file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\pytorch_model.bin\n",
      "I0218 13:49:55.601846  1140 tokenization_utils.py:327] Model name 'C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1). Assuming 'C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT' is a path or url to a directory containing tokenizer files.\n",
      "I0218 13:49:55.617473  1140 tokenization_utils.py:359] Didn't find file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\tokenizer_config.json. We won't load it.\n",
      "I0218 13:49:55.617473  1140 tokenization_utils.py:395] loading file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\vocab.txt\n",
      "I0218 13:49:55.617473  1140 tokenization_utils.py:395] loading file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\added_tokens.json\n",
      "I0218 13:49:55.633096  1140 tokenization_utils.py:395] loading file C:\\Users\\ApotheekStiens/.cache\\torch\\sentence_transformers\\public.ukp.informatik.tu-darmstadt.de_reimers_sentence-transformers_v0.2_bert-base-nli-mean-tokens.zip\\0_BERT\\special_tokens_map.json\n",
      "I0218 13:49:55.633096  1140 tokenization_utils.py:395] loading file None\n",
      "I0218 13:49:55.883099  1140 SentenceTransformer.py:89] Use pytorch device: cpu\n",
      "Batches: 100%|███████████████████████████████████| 2/2 [00:00<00:00,  1.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster  1\n",
      "['A man is eating food.', 'A man is eating a piece of bread.', 'A man is eating pasta.']\n",
      "\n",
      "Cluster  2\n",
      "['A cheetah is running behind its prey.', 'A cheetah chases prey on across a field.']\n",
      "\n",
      "Cluster  3\n",
      "['The girl is carrying a baby.', 'The baby is carried by the woman']\n",
      "\n",
      "Cluster  4\n",
      "['A monkey is playing drums.', 'Someone in a gorilla costume is playing a set of drums.']\n",
      "\n",
      "Cluster  5\n",
      "['A man is riding a horse.', 'A man is riding a white horse on an enclosed ground.']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is a simple application for sentence embeddings: clustering\n",
    "Sentences are mapped to sentence embeddings and then k-mean clustering is applied.\n",
    "\"\"\"\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "embedder = SentenceTransformer('bert-base-nli-mean-tokens')\n",
    "\n",
    "# Corpus with example sentences\n",
    "corpus = ['A man is eating food.',\n",
    "          'A man is eating a piece of bread.',\n",
    "          'A man is eating pasta.',\n",
    "          'The girl is carrying a baby.',\n",
    "          'The baby is carried by the woman',\n",
    "          'A man is riding a horse.',\n",
    "          'A man is riding a white horse on an enclosed ground.',\n",
    "          'A monkey is playing drums.',\n",
    "          'Someone in a gorilla costume is playing a set of drums.',\n",
    "          'A cheetah is running behind its prey.',\n",
    "          'A cheetah chases prey on across a field.'\n",
    "          ]\n",
    "corpus_embeddings = embedder.encode(corpus)\n",
    "\n",
    "# Perform kmean clustering\n",
    "num_clusters = 5\n",
    "clustering_model = KMeans(n_clusters=num_clusters)\n",
    "clustering_model.fit(corpus_embeddings)\n",
    "cluster_assignment = clustering_model.labels_\n",
    "\n",
    "clustered_sentences = [[] for i in range(num_clusters)]\n",
    "for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
    "    clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
    "\n",
    "for i, cluster in enumerate(clustered_sentences):\n",
    "    print(\"Cluster \", i+1)\n",
    "    print(cluster)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
